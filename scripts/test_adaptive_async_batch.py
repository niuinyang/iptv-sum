import argparse
import csv
import os
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
from statistics import mean

# ==============================
# å‘½ä»¤è¡Œå‚æ•°
# ==============================
parser = argparse.ArgumentParser()
parser.add_argument("--csv", default="output/merge_total.csv", help="è¾“å…¥ CSV æ–‡ä»¶ï¼Œé»˜è®¤ merge_total.csv")
parser.add_argument("--m3u", default="output/working.m3u", help="è¾“å‡º M3U æ–‡ä»¶")
args = parser.parse_args()

CSV_FILE = args.csv
OUTPUT_FILE = args.m3u

# ==============================
# é…ç½®
# ==============================
TIMEOUT = 10
MAX_THREADS = 50
skipped_file = "output/log/skipped.log"
os.makedirs(os.path.dirname(skipped_file), exist_ok=True)

# ==============================
# è¯»å– CSV
# ==============================
if not os.path.exists(CSV_FILE):
    print(f"âŒ è¾“å…¥ CSV ä¸å­˜åœ¨: {CSV_FILE}")
    exit(1)

channels = []
with open(CSV_FILE, encoding="utf-8") as f:
    reader = csv.DictReader(f)
    for row in reader:
        channels.append({
            "name": row["tvg-name"],
            "url": row["URL"],
            "group": row.get("åœ°åŒº", ""),
            "source": row.get("æ¥æº", "")
        })

print(f"ğŸ“„ è¯»å– CSV {CSV_FILE}ï¼Œå…± {len(channels)} æ¡é¢‘é“")

# ==============================
# æ£€æµ‹å‡½æ•°
# ==============================
def check_stream(channel):
    url = channel["url"]
    try:
        r = requests.head(url, timeout=TIMEOUT, allow_redirects=True)
        if r.status_code == 200:
            return channel
        else:
            with open(skipped_file, "a", encoding="utf-8") as f:
                f.write(f"{channel['name']},{url},çŠ¶æ€ç :{r.status_code}\n")
            return None
    except Exception as e:
        with open(skipped_file, "a", encoding="utf-8") as f:
            f.write(f"{channel['name']},{url},å¼‚å¸¸:{e}\n")
        return None

# ==============================
# æ‰¹é‡æ£€æµ‹
# ==============================
working_channels = []
with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
    future_to_channel = {executor.submit(check_stream, ch): ch for ch in channels}
    for future in as_completed(future_to_channel):
        result = future.result()
        if result:
            working_channels.append(result)

# ==============================
# è¾“å‡º M3U
# ==============================
with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    f.write("#EXTM3U\n")
    for ch in working_channels:
        extinf = f'#EXTINF:-1 tvg-name="{ch["name"]}" group-title="{ch["group"]}",{ch["name"]}'
        f.write(f"{extinf}\n{ch['url']}\n")

print(f"âœ… æ£€æµ‹å®Œæˆï¼Œå¯ç”¨é¢‘é“ {len(working_channels)} æ¡ï¼Œè¾“å‡º M3U: {OUTPUT_FILE}")
print(f"âš ï¸ å¤±è´¥æˆ–è·³è¿‡æºå·²è®°å½•åœ¨ {skipped_file}")