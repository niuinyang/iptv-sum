import aiohttp
import asyncio
import os
import time
import random
import requests
from aiohttp import ClientTimeout

# ==============================
# é…ç½®åŒº
# ==============================
SOURCE_LIST = [
    "https://freetv.fun/test_channels_taiwan_new.m3u",
    "https://freetv.fun/test_channels_hong_kong_new.m3u",
    "https://freetv.fun/test_channels_macau_new.m3u",
    "https://freetv.fun/test_channels_singapore_new.m3u",
    "https://freetv.fun/test_channels_united_states_new.m3u"
]

# å¯é€‰ä»£ç†å¤‡ç”¨å‰ç¼€ï¼ˆé€šè¿‡ jsDelivr æˆ– Cloudflare Worker ä»£ç† freetv.funï¼‰
PROXY_PREFIXES = [
    "https://cdn.jsdelivr.net/gh/freetvsource/proxy@main/?url=",
    "https://workers.cloudflare.com/?url="
]

OUTPUT_DIR = "input/network/network_sources"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# å¤šä¸ª UA éšæœºä½¿ç”¨ï¼Œæ¨¡æ‹Ÿä¸åŒå®¢æˆ·ç«¯
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/128.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 13_0) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) Gecko/20100101 Firefox/129.0",
    "Mozilla/5.0 (Android 13; Mobile) AppleWebKit/537.36 Chrome/128.0.6613.138 Mobile Safari/537.36"
]

MAX_RETRIES = 3
TIMEOUT = 20


# ==============================
# å¼‚æ­¥ä¸‹è½½å‡½æ•°
# ==============================
async def fetch(session, url):
    filename = os.path.join(OUTPUT_DIR, os.path.basename(url))
    headers = {"User-Agent": random.choice(USER_AGENTS), "Referer": "https://freetv.fun/"}

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            await asyncio.sleep(random.uniform(1.5, 3.5))  # éšæœºå»¶è¿Ÿé˜²å°
            async with session.get(url, timeout=ClientTimeout(total=TIMEOUT)) as resp:
                if resp.status == 200:
                    text = await resp.text()
                    with open(filename, "w", encoding="utf-8") as f:
                        f.write(text)
                    print(f"âœ… ä¸‹è½½æˆåŠŸ: {url} â†’ {filename}")
                    return
                else:
                    print(f"âš ï¸ [{resp.status}] æ— æ³•ä¸‹è½½: {url} (å°è¯• {attempt}/{MAX_RETRIES})")
        except Exception as e:
            print(f"âš ï¸ å¼‚æ­¥é”™è¯¯ ({attempt}/{MAX_RETRIES}): {url} -> {e}")
        await asyncio.sleep(2)

    # å°è¯•ä»£ç†ä¸‹è½½
    for proxy_prefix in PROXY_PREFIXES:
        proxy_url = proxy_prefix + url
        print(f"ğŸ” å°è¯•ä»£ç†ä¸‹è½½: {proxy_url}")
        try:
            resp = requests.get(proxy_url, headers=headers, timeout=TIMEOUT)
            if resp.status_code == 200 and "#EXTM3U" in resp.text:
                with open(filename, "w", encoding="utf-8") as f:
                    f.write(resp.text)
                print(f"âœ… ä»£ç†ä¸‹è½½æˆåŠŸ: {proxy_url}")
                return
            else:
                print(f"âŒ ä»£ç†å¤±è´¥ ({resp.status_code}): {proxy_url}")
        except Exception as e:
            print(f"âŒ ä»£ç†å¼‚å¸¸: {proxy_url} -> {e}")

    print(f"âŒ æœ€ç»ˆä¸‹è½½å¤±è´¥: {url}")


# ==============================
# ä¸»ä»»åŠ¡
# ==============================
async def main():
    async with aiohttp.ClientSession() as session:
        tasks = [fetch(session, url) for url in SOURCE_LIST]
        await asyncio.gather(*tasks)


# ==============================
# ä¸»å…¥å£
# ==============================
if __name__ == "__main__":
    start_time = time.time()
    print("ğŸ“¡ å¼€å§‹ä¸‹è½½ M3U æºæ–‡ä»¶...\n")

    try:
        asyncio.run(main())
    except Exception as e:
        print(f"âŒ ä¸»ä»»åŠ¡å¼‚å¸¸: {e}")

    print(f"\nâœ… å…¨éƒ¨ä¸‹è½½ä»»åŠ¡å®Œæˆï¼Œç”¨æ—¶ {time.time() - start_time:.1f} ç§’ã€‚")
