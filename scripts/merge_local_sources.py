import os
import csv
import requests
from pathlib import Path

# ==============================
# è·¯å¾„é…ç½®ï¼ˆå·²æ›´æ–°ï¼‰
# ==============================
INPUT_DIR = Path("input/network/network_sources")
OUTPUT_DIR = Path("output")
LOG_DIR = OUTPUT_DIR / "log"
MIDDLE_DIR = OUTPUT_DIR / "middle"

for p in [OUTPUT_DIR, LOG_DIR, MIDDLE_DIR]:
    p.mkdir(parents=True, exist_ok=True)

MERGE_M3U = OUTPUT_DIR / "merge_total.m3u"
MERGE_CSV = OUTPUT_DIR / "total.csv"

# ==============================
# æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚å¤´
# ==============================
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Encoding": "gzip, deflate, br",
    "Connection": "keep-alive",
}

# ==============================
# å‡½æ•°ï¼šåŠ è½½ M3U æ–‡ä»¶ï¼ˆæœ¬åœ°ï¼‰
# ==============================
def load_local_m3u(path: Path):
    try:
        text = path.read_text(encoding="utf-8").strip()
        if not text.startswith("#EXTM3U"):
            raise ValueError("ä¸æ˜¯åˆæ³•çš„ M3U æ–‡ä»¶")
        return text.splitlines()
    except Exception as e:
        print(f"âš ï¸ è¯»å– {path.name} å¤±è´¥: {e}")
        return []

# ==============================
# ä¸»å‡½æ•°ï¼šåˆå¹¶æ‰€æœ‰æº
# ==============================
def merge_sources():
    merged_entries = []
    seen_urls = set()
    total_sources = 0
    failed_sources = 0

    for file in INPUT_DIR.glob("*.m3u"):
        print(f"ğŸ“¡ è¯»å–æºæ–‡ä»¶: {file.name}")
        lines = load_local_m3u(file)

        if not lines:
            print(f"âš ï¸ æºæ–‡ä»¶ä¸ºç©ºæˆ–æ— æ•ˆ: {file.name}")
            failed_sources += 1
            continue

        total_sources += 1
        current_info = None

        for line in lines:
            line = line.strip()
            if line.startswith("#EXTINF:"):
                current_info = line
            elif line.startswith("http"):
                url = line
                if url not in seen_urls:
                    merged_entries.append((current_info, url))
                    seen_urls.add(url)

    # è¾“å‡ºç»“æœ
    if not merged_entries:
        print("âš ï¸ æ²¡æœ‰åˆå¹¶åˆ°ä»»ä½•é¢‘é“ï¼")
    else:
        with open(MERGE_M3U, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
            for info, url in merged_entries:
                f.write(f"{info}\n{url}\n")

        with open(MERGE_CSV, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerow(["#EXTINF", "URL"])
            for info, url in merged_entries:
                writer.writerow([info, url])

        print(f"âœ… åˆå¹¶å®Œæˆï¼šæˆåŠŸ {total_sources} æºï¼Œå¤±è´¥ {failed_sources} æºï¼Œ"
              f"å»é‡å {len(merged_entries)} æ¡é¢‘é“ â†’ {MERGE_M3U} / {MERGE_CSV}")
        print(f"ğŸ“ ä¸­é—´æ–‡ä»¶ â†’ {MIDDLE_DIR}")
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶ â†’ {LOG_DIR}/skipped.log")


# ==============================
# ä¸»ç¨‹åºå…¥å£
# ==============================
if __name__ == "__main__":
    merge_sources()