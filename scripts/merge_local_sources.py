import os
import re
import csv
import unicodedata

# ==============================
# é…ç½®åŒº
# ==============================
SOURCE_DIR = "input/network/network_sources"  # ä¸‹è½½æºç›®å½•
ICON_DIR = "png"                              # æœ¬åœ°å›¾æ ‡ç›®å½•
OUTPUT_DIR = "output"
LOG_DIR = os.path.join(OUTPUT_DIR, "log")

os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

OUTPUT_M3U = os.path.join(OUTPUT_DIR, "merge_total.m3u")
OUTPUT_CSV = os.path.join(OUTPUT_DIR, "merge_total.csv")
SKIPPED_LOG = os.path.join(LOG_DIR, "skipped.log")

# ==============================
# å·¥å…·å‡½æ•°
# ==============================
def normalize_channel_name(name: str) -> str:
    """æ ‡å‡†åŒ–é¢‘é“åï¼ˆå»æ‰ç¬¦å·ã€ç©ºæ ¼ã€ç»Ÿä¸€å¤§å°å†™ï¼‰"""
    name = unicodedata.normalize("NFKC", name)
    name = re.sub(r"[\s\[\]ï¼ˆï¼‰()ã€ã€‘]", "", name)
    name = re.sub(r"[-_\.]", "", name)
    return name.strip().lower()


def get_icon_path(name: str) -> str:
    """è·å–å›¾æ ‡è·¯å¾„ï¼ˆæœ¬åœ°ä¼˜å…ˆï¼Œå¦åˆ™ç”¨è¿œç¨‹é“¾æ¥ï¼‰"""
    local_path = os.path.join(ICON_DIR, f"{name}.png")
    if os.path.exists(local_path):
        return local_path
    encoded_name = re.sub(r"\s+", "", name)
    return f"https://epg.pw/media/logo/{encoded_name}.png"


def read_m3u_file(file_path: str):
    """è¯»å– M3U æ–‡ä»¶ï¼Œè¿”å› (é¢‘é“å, URL) åˆ—è¡¨"""
    channels = []
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            lines = f.readlines()

        i = 0
        while i < len(lines):
            line = lines[i].strip()
            if line.startswith("#EXTINF:"):
                info_line = line
                url_line = lines[i + 1].strip() if i + 1 < len(lines) else ""
                match = re.search(r'tvg-name="([^"]+)"', info_line)
                name = match.group(1) if match else "æœªçŸ¥é¢‘é“"
                channels.append((name, url_line))
                i += 2
            else:
                i += 1

        print(f"ğŸ“¡ å·²åŠ è½½ {os.path.basename(file_path)}: {len(channels)} æ¡é¢‘é“")
        return channels

    except Exception as e:
        print(f"âš ï¸ è¯»å– {file_path} å¤±è´¥: {e}")
        return []


# ==============================
# ä¸»é€»è¾‘ï¼ˆå»é‡ç›¸åŒ URLï¼‰
# ==============================
def merge_local_sources():
    all_channels = []
    skipped = []
    seen_urls = set()

    print(f"ğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶å¤¹: {os.path.abspath(SOURCE_DIR)}")

    for file in os.listdir(SOURCE_DIR):
        if not file.endswith(".m3u"):
            continue
        file_path = os.path.join(SOURCE_DIR, file)
        channels = read_m3u_file(file_path)

        for name, url in channels:
            if not url.startswith("http"):
                skipped.append((name, url))
                continue
            if url in seen_urls:
                continue
            seen_urls.add(url)
            all_channels.append((name, url))

    print(f"\nâœ… åˆå¹¶å®Œæˆï¼šå…± {len(all_channels)} æ¡é¢‘é“ï¼ˆå·²å»é‡ç›¸åŒ URLï¼‰")

    # ==============================
    # å†™å…¥ M3Uï¼ˆtvg-name ç”¨æ ‡å‡†åŒ–åï¼‰
    # ==============================
    with open(OUTPUT_M3U, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        for name, url in all_channels:
            normalized = normalize_channel_name(name)
            logo = get_icon_path(name)
            f.write(f'#EXTINF:-1 tvg-name="{normalized}" tvg-logo="{logo}",{name}\n{url}\n')

    # ==============================
    # å†™å…¥ CSVï¼ˆåˆ—é¡ºåºç¬¦åˆè¦æ±‚ï¼‰
    # ==============================
    with open(OUTPUT_CSV, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["normalized_name", "", "URL", "æ¥æº", "tvg-name", "icon_url"])
        for name, url in all_channels:
            normalized = normalize_channel_name(name)
            icon = get_icon_path(name)
            writer.writerow([normalized, "", url, "ç½‘ç»œæº", name, icon])

    # ==============================
    # å†™å…¥è·³è¿‡æ—¥å¿—
    # ==============================
    with open(SKIPPED_LOG, "w", encoding="utf-8") as f:
        for name, url in skipped:
            f.write(f"{name},{url}\n")

    print(f"ğŸ“ M3U è¾“å‡º: {OUTPUT_M3U}")
    print(f"ğŸ“ CSV è¾“å‡º: {OUTPUT_CSV}")
    print(f"ğŸ“ è·³è¿‡æ—¥å¿—: {SKIPPED_LOG}")
    print("âœ… æ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")


# ==============================
# ä¸»å…¥å£
# ==============================
if __name__ == "__main__":
    merge_local_sources()