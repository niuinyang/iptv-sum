import requests, os, time, re

# ------------------- é…ç½® -------------------
sources_file = "input/network/networksource.txt"
output_file = "output/total.m3u"
os.makedirs("output", exist_ok=True)

headers = {"User-Agent": "Mozilla/5.0"}
all_lines = []
success, failed = 0, 0

# ------------------- è¯»å–æºåˆ—è¡¨ -------------------
with open(sources_file, "r", encoding="utf-8") as f:
    urls = [u.strip() for u in f if u.strip() and not u.strip().startswith("#")]

for url in urls:
    print(f"ğŸ“¡ Fetching: {url}")
    try:
        if url.startswith("http"):
            text = None
            for attempt in range(3):
                try:
                    r = requests.get(url, headers=headers, timeout=15)
                    r.encoding = r.apparent_encoding or "utf-8"
                    text = r.text
                    break
                except Exception as e:
                    print(f"âš ï¸ é‡è¯• {attempt+1}/3 å¤±è´¥: {e}")
                    time.sleep(2)
            if text is None:
                raise Exception("3æ¬¡é‡è¯•å¤±è´¥")
        else:
            with open(url, encoding="utf-8", errors="ignore") as f2:
                text = f2.read()

        # ä¿ç•™æ‰€æœ‰è¡Œï¼Œå»æ‰æ–‡ä»¶å¤´ #EXTM3U
        lines = [l.strip() for l in text.splitlines() if l.strip() and not l.strip().startswith("#EXTM3U")]
        all_lines.extend(lines)
        success += 1
    except Exception as e:
        failed += 1
        print(f"âŒ Failed: {url} ({e})")

# ------------------- ç»„åˆ EXTINF + URL å¯¹ -------------------
pairs = []
url_pattern = re.compile(r'^https?://')
for i, line in enumerate(all_lines):
    if line.startswith("#EXTINF"):
        # å‘ä¸‹æ‰¾ç¬¬ä¸€ä¸ª URL
        for j in range(i+1, len(all_lines)):
            if url_pattern.match(all_lines[j]):
                pairs.append((line, all_lines[j]))
                break

# ------------------- å»é‡ (å®Œå…¨é‡å¤çš„ EXTINF+URL) -------------------
seen = set()
unique_pairs = []
for title, url in pairs:
    key = (title, url)
    if key not in seen:
        unique_pairs.append((title, url))
        seen.add(key)

# ------------------- è‡ªç„¶æ’åº -------------------
def natural_key(text):
    return [int(t) if t.isdigit() else t.lower() for t in re.split("([0-9]+)", text)]

unique_pairs.sort(key=lambda x: natural_key(x[0]))

# ------------------- å†™å…¥ total.m3u -------------------
with open(output_file, "w", encoding="utf-8") as f:
    f.write("#EXTM3U\n")
    for title, url in unique_pairs:
        f.write(f"{title}\n{url}\n")

print(f"\nâœ… åˆå¹¶å®Œæˆï¼šæˆåŠŸ {success} æºï¼Œå¤±è´¥ {failed} æºï¼Œ"
      f"å»é‡å {len(unique_pairs)} æ¡é¢‘é“ â†’ {output_file}")
