import requests, os

sources_file = "m3u_sources/list.txt"
output_file = "output/total.m3u"

os.makedirs("output", exist_ok=True)

# ------------------- è¯»å–æ‰€æœ‰æºå¹¶åˆå¹¶ -------------------
all_lines = []

with open(sources_file, "r", encoding="utf-8") as f:
    for url in f:
        url = url.strip()
        if not url or url.startswith("#"):
            continue
        print(f"ğŸ“¡ Fetching: {url}")
        try:
            if url.startswith("http"):
                text = requests.get(url, timeout=10).text
            else:
                with open(url, encoding="utf-8") as f2:
                    text = f2.read()
            # å¿½ç•¥æ–‡ä»¶å¤´ #EXTM3U
            all_lines.extend([l for l in text.splitlines() if not l.strip().startswith("#EXTM3U")])
        except Exception as e:
            print(f"âŒ Failed: {url} ({e})")

# ------------------- ç»„åˆæˆ EXTINF + URL å¯¹ -------------------
pairs = [(all_lines[i], all_lines[i+1]) for i in range(len(all_lines)-1) if all_lines[i].startswith("#EXTINF")]

# ------------------- URL å»é‡ -------------------
seen_urls = set()
unique_pairs = []
for title, url in pairs:
    if url not in seen_urls:
        unique_pairs.append((title, url))
        seen_urls.add(url)

# ------------------- å†™å…¥ total.m3u -------------------
with open(output_file, "w", encoding="utf-8") as f:
    f.write("#EXTM3U\n")
    for title, url in unique_pairs:
        f.write(f"{title}\n{url}\n")

print(f"âœ… åˆå¹¶å®Œæˆï¼ˆå»é‡å {len(unique_pairs)} æ¡æºï¼‰: {output_file}")
