import os
import csv
import re
from collections import defaultdict

# ==============================
# æ–‡ä»¶å¤¹å’Œå›¾æ ‡é…ç½®
# ==============================
icon_dir = "png"
default_icon = os.path.join(icon_dir, "default.png")
output_dir = "output"
os.makedirs(output_dir, exist_ok=True)

fixed_csv = ["input/mysource/my_sum.csv"]
fixed_folder = "input/network/manual"
extra_folder = "output/sum_cvs"

# ==============================
# åˆ†ç»„ä¼˜å…ˆçº§
# ==============================
group_order = [
    "å¤®è§†é¢‘é“", "å«è§†é¢‘é“", "å°æ¹¾é¢‘é“", "é¦™æ¸¯é¢‘é“",
    "æ¾³é—¨é¢‘é“", "å›½é™…é¢‘é“", "åœ°æ–¹é¢‘é“", "æ•°å­—é¢‘é“"
]

# ==============================
# æºä¼˜å…ˆçº§
# ==============================
dxl_priority = ["ç”µä¿¡ç»„æ’­", "æµå—è”é€š", "ä¸Šæµ·ç§»åŠ¨", "ç”µä¿¡å•æ’­", "é’å²›è”é€š"]
sjmz_priority = ["æµå—ç§»åŠ¨", "ä¸Šæµ·ç§»åŠ¨", "æµå—è”é€š", "ç”µä¿¡ç»„æ’­", "é’å²›è”é€š", "ç”µä¿¡å•æ’­"]

# ==============================
# åˆ†ç»„æ˜ å°„
# ==============================
GROUP_MAP = {
    "å°æ¹¾": "å°æ¹¾é¢‘é“",
    "é¦™æ¸¯": "é¦™æ¸¯é¢‘é“",
    "æ¾³é—¨": "æ¾³é—¨é¢‘é“",
    "å›½é™…": "å›½é™…é¢‘é“",
    "tw": "å°æ¹¾é¢‘é“",
    "hk": "é¦™æ¸¯é¢‘é“",
    "mo": "æ¾³é—¨é¢‘é“",
    "intl": "å›½é™…é¢‘é“"
}

# ==============================
# è¯»å– CSV
# ==============================
def read_csv_files(paths, manual_group_map=None):
    channels = []
    for path in paths:
        if not os.path.exists(path):
            print(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: {path}")
            continue
        if os.path.isdir(path):
            for file in os.listdir(path):
                if file.endswith(".csv"):
                    channels += read_csv_files([os.path.join(path, file)], manual_group_map)
        else:
            with open(path, encoding="utf-8") as f:
                sample = f.read(1024)
                f.seek(0)
                delimiter = "\t" if "\t" in sample else ","
                reader = csv.reader(f, delimiter=delimiter)
                count = 0
                filename = os.path.basename(path).lower()
                for row in reader:
                    if len(row) >= 4:
                        name, group, url, source = row[:4]
                    elif len(row) == 2 and manual_group_map:
                        name, url = row
                        group = manual_group_map.get(filename, "æœªåˆ†ç±»")
                        source = "æ‰‹åŠ¨"
                    else:
                        continue
                    # æ˜ å°„åˆ†ç»„åç§°
                    group = GROUP_MAP.get(group.strip(), group.strip())
                    channels.append({
                        "name": name.strip(),
                        "group": group,
                        "url": url.strip(),
                        "source": source.strip()
                    })
                    count += 1
                print(f"ğŸ“„ è¯»å– {path} å…± {count} æ¡æ•°æ®")
    return channels

# ==============================
# æ’åºè§„åˆ™
# ==============================
def natural_key(name):
    m = re.match(r"CCTV(\d+)", name.upper())
    if m:
        return (0, int(m.group(1)))
    return (1, name.lower())

def group_key(group):
    if group in group_order:
        return group_order.index(group)
    return len(group_order)

def source_priority(source, order):
    try:
        return order.index(source)
    except ValueError:
        return len(order)

# ==============================
# M3U ç”Ÿæˆå‡½æ•°
# ==============================
def write_m3u(channels_dict, output_file, source_order=None, exclude_sources=None):
    total = 0
    exclude_sources = exclude_sources or []
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        for group, name_dict in sorted(channels_dict.items(), key=lambda x: group_key(x[0])):
            for name, sources in sorted(name_dict.items(), key=lambda x: natural_key(x[0])):
                filtered_sources = [s for s in sources if s["source"] not in exclude_sources]
                if source_order:
                    filtered_sources.sort(key=lambda s: source_priority(s["source"], source_order))
                for s in filtered_sources:
                    logo_path = os.path.join(icon_dir, f"{name}.png")
                    logo = logo_path if os.path.exists(logo_path) else default_icon
                    extinf = f'#EXTINF:-1 tvg-name="{name}" tvg-logo="{logo}" group-title="{s["group"]}",{name}'
                    f.write(f"{extinf}\n{s['url']}\n")
                    total += 1
    print(f"âœ… å·²ç”Ÿæˆ {output_file}ï¼Œå…± {total} æ¡é¢‘é“")

# ==============================
# ä¸»ç¨‹åº
# ==============================
def main():
    # æ‰‹åŠ¨ CSV åˆ†ç»„æ˜ å°„
    manual_group_map = {
        "network_hk_manual.csv": "é¦™æ¸¯é¢‘é“",
        "network_mo_manual.csv": "æ¾³é—¨é¢‘é“",
        "network_tw_manual.csv": "å°æ¹¾é¢‘é“",
        "netwotk_intl_manual.csv": "å›½é™…é¢‘é“"
    }

    # å›ºå®šæº
    fixed_channels = read_csv_files(fixed_csv + [fixed_folder], manual_group_map)

    # å»ºç«‹å›ºå®šæºé¢‘é“åé›†åˆï¼ˆæ­£åˆ™åŒ¹é…ç”¨ï¼‰
    fixed_names = [re.escape(ch["name"]) for ch in fixed_channels]
    fixed_pattern = re.compile("|".join(fixed_names), re.I)

    # è¡¥å……æº
    extra_channels = read_csv_files([extra_folder])

    # è¡¥å……æºåªä¿ç•™å›ºå®šæºå·²æœ‰çš„é¢‘é“
    extra_filtered = [ch for ch in extra_channels if fixed_pattern.search(ch["name"])]

    # åˆå¹¶é¢‘é“
    combined = defaultdict(lambda: defaultdict(list))
    for ch in fixed_channels:
        combined[ch["group"]][ch["name"]].append(ch)
    for ch in extra_filtered:
        combined[ch["group"]][ch["name"]].append(ch)

    # ç”Ÿæˆ M3U æ–‡ä»¶
    write_m3u(combined, os.path.join(output_dir, "total.m3u"))
    write_m3u(combined, os.path.join(output_dir, "dxl.m3u"), source_order=dxl_priority, exclude_sources=["æµå—ç§»åŠ¨"])
    write_m3u(combined, os.path.join(output_dir, "sjmz.m3u"), source_order=sjmz_priority)

    print("âœ… æ‰€æœ‰ M3U æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")

if __name__ == "__main__":
    main()